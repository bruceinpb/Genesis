/**
 * Genesis 2 — OpenAI API Integration Module
 * Handles cross-model prose scoring (GPT-5.2) and image generation (GPT Image 1.5).
 * Provides graceful degradation: if OpenAI is unavailable, the system falls back
 * to Claude-only scoring and HuggingFace-only images.
 */

const OPENAI_API_URL = 'https://api.openai.com/v1';

// Cross-model scoring system prompt — GPT evaluates prose generated by Claude
const CROSS_MODEL_SCORING_SYSTEM_PROMPT = `You are an adversarial prose quality assessor. You are evaluating prose that was generated by a DIFFERENT AI system. Your job is to catch patterns and weaknesses that the generating system cannot see in its own output.

Score the following passage on these dimensions (each 1-15):

1. AUTHENTICITY — Does this read like a human wrote it? Flag any patterns that feel AI-generated: over-polish, balanced sentence pairs, formulaic emotional beats, "telling" instead of "showing", predictable metaphor placement.

2. PROSE CRAFT — Sentence-level quality. Variation in rhythm, precise word choices, avoidance of clich\u00e9, natural dialogue (if present).

3. EMOTIONAL TRUTH — Does the emotional content feel earned and specific, or generic and performative? Real human writing has uneven emotional textures.

4. SENSORY SPECIFICITY — Concrete sensory details that ground the reader in place and moment. Penalize vague or decorative sensory language.

5. NARRATIVE MOMENTUM — Does the passage pull the reader forward? Pacing, tension, withholding, and release.

6. AI PATTERN DETECTION — Specifically flag:
   - Paired/balanced constructions ("X, but Y" / "not just A, but B")
   - Performative introspection (characters observing their own emotions)
   - Metaphor clustering (too many figurative phrases in proximity)
   - Emotional escalation without cause
   - "Literary" filler that sounds good but adds nothing
   - Excessive interiority without action

Return JSON only:
{
  "scores": { "authenticity": N, "craft": N, "emotion": N, "sensory": N, "momentum": N, "ai_detection": N },
  "total": N,
  "ai_patterns_found": ["pattern1", "pattern2"],
  "weakest_line": "quote the weakest sentence",
  "verdict": "PASS" | "FAIL" | "REVISE",
  "revision_notes": "specific fixes if REVISE"
}`;

class OpenAIClient {
  constructor(storage) {
    this.storage = storage;
    this.apiKey = null;
    this.model = 'gpt-5.2';
    this.imageModel = 'gpt-image-1.5';
    this.enabled = false;
    this.crossModelScoring = true;
    this.imageTier = 'backup'; // 'backup' | 'primary' | 'hero-only'
  }

  async init() {
    this.apiKey = (await this.storage.getSetting('openaiApiKey', '') || '').trim();
    this.model = await this.storage.getSetting('openaiModel', 'gpt-5.2');
    this.imageModel = await this.storage.getSetting('openaiImageModel', 'gpt-image-1.5');
    this.enabled = !!this.apiKey;
    this.crossModelScoring = (await this.storage.getSetting('crossModelScoring', 'true')) !== 'false';
    this.imageTier = await this.storage.getSetting('openaiImageTier', 'backup');
  }

  async setApiKey(key) {
    this.apiKey = (key || '').trim();
    this.enabled = !!this.apiKey;
    await this.storage.setSetting('openaiApiKey', this.apiKey);
  }

  async setModel(model) {
    this.model = model;
    await this.storage.setSetting('openaiModel', model);
  }

  async setImageModel(model) {
    this.imageModel = model;
    await this.storage.setSetting('openaiImageModel', model);
  }

  async setCrossModelScoring(enabled) {
    this.crossModelScoring = enabled;
    await this.storage.setSetting('crossModelScoring', enabled ? 'true' : 'false');
  }

  async setImageTier(tier) {
    this.imageTier = tier;
    await this.storage.setSetting('openaiImageTier', tier);
  }

  isConfigured() {
    return this.enabled && !!this.apiKey;
  }

  // === KEY VALIDATION ===

  async validateKey(key) {
    try {
      const response = await fetch(`${OPENAI_API_URL}/models`, {
        method: 'GET',
        headers: {
          'Authorization': `Bearer ${key}`
        }
      });

      if (response.ok) {
        return { valid: true, status: 'connected' };
      } else if (response.status === 401) {
        return { valid: false, status: 'invalid' };
      } else {
        return { valid: false, status: 'error', code: response.status };
      }
    } catch (err) {
      return { valid: false, status: 'error', message: err.message };
    }
  }

  // === CROSS-MODEL PROSE SCORING ===

  async scorePassage(passageText, genre, subgenre, pov) {
    if (!this.isConfigured() || !this.crossModelScoring) return null;

    try {
      const response = await fetch(`${OPENAI_API_URL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: this.model,
          messages: [
            { role: 'system', content: CROSS_MODEL_SCORING_SYSTEM_PROMPT },
            {
              role: 'user',
              content: `Genre: ${genre || 'literary fiction'} | Subgenre: ${subgenre || 'general'} | POV: ${pov || 'third person'}\n\nPassage to score:\n---\n${passageText}\n---`
            }
          ],
          max_tokens: 800,
          temperature: 0.3
        })
      });

      if (!response.ok) {
        console.warn('OpenAI cross-model scoring failed:', response.status);
        return null; // Graceful degradation
      }

      const data = await response.json();
      const text = data.choices[0].message.content;

      // Parse JSON from response (handle code fences)
      const clean = text.replace(/```json\n?|```\n?/g, '').trim();
      const jsonMatch = clean.match(/\{[\s\S]*\}/);
      return JSON.parse(jsonMatch ? jsonMatch[0] : clean);
    } catch (err) {
      console.warn('OpenAI cross-model scoring error:', err.message);
      return null; // Graceful degradation — never block generation
    }
  }

  // === COMBINED VERDICT LOGIC ===

  getCombinedVerdict(claudeScore, gptScore) {
    if (!gptScore) {
      // No GPT score available — use Claude-only
      return { verdict: claudeScore.total >= 70 ? 'PASS' : 'FAIL', gptAvailable: false };
    }

    const claudeTotal = typeof claudeScore === 'number' ? claudeScore : (claudeScore.score || claudeScore.total || 0);
    const gptTotal = gptScore.total || 0;

    // Both must pass for PASS
    if (claudeTotal >= 70 && gptTotal >= 65) {
      return { verdict: 'PASS', gptAvailable: true, claudeTotal, gptTotal };
    }

    // If Claude passes but GPT flags AI patterns
    if (claudeTotal >= 70 && (gptScore.ai_patterns_found || []).length >= 3) {
      return {
        verdict: 'REVISE',
        gptAvailable: true,
        claudeTotal,
        gptTotal,
        reason: `GPT flagged ${gptScore.ai_patterns_found.length} AI patterns`
      };
    }

    // If scores are wildly divergent, flag for review
    if (Math.abs(claudeTotal - gptTotal) > 20) {
      return {
        verdict: 'REVIEW',
        gptAvailable: true,
        claudeTotal,
        gptTotal,
        reason: `Score divergence: Claude ${claudeTotal} vs GPT ${gptTotal}`
      };
    }

    return { verdict: 'FAIL', gptAvailable: true, claudeTotal, gptTotal };
  }

  // === IMAGE GENERATION ===

  async generateImage(prompt, size = '1024x1024', quality = 'low') {
    if (!this.isConfigured()) throw new Error('OpenAI not configured');

    const response = await fetch(`${OPENAI_API_URL}/images/generations`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      },
      body: JSON.stringify({
        model: this.imageModel,
        prompt: prompt,
        n: 1,
        size: size,
        quality: quality,
        output_format: 'png'
      })
    });

    if (!response.ok) {
      const err = await response.json().catch(() => ({}));
      throw new Error(`OpenAI image error: ${err.error?.message || response.status}`);
    }

    const data = await response.json();
    const base64 = data.data[0].b64_json;
    return base64ToBlob(base64, 'image/png');
  }

  // Returns config for tiered image generation
  getImageConfig(tier) {
    switch (tier) {
      case 'preview':
        return {
          size: '1024x1024', quality: 'low',
          width: 1024, height: 1024,
          estimatedCost: 0.009
        };
      case 'standard':
        return {
          size: '1024x1024', quality: 'low',
          width: 1024, height: 1024,
          estimatedCost: 0.009
        };
      case 'print':
        return {
          size: '1024x1536', quality: 'high',
          width: 1024, height: 1536,
          estimatedCost: 0.20
        };
      default:
        return {
          size: '1024x1024', quality: 'low',
          width: 1024, height: 1024,
          estimatedCost: 0.009
        };
    }
  }

  // Generate image at a specific tier
  async generateTieredImage(prompt, tier = 'standard') {
    const config = this.getImageConfig(tier);
    const blob = await this.generateImage(prompt, config.size, config.quality);
    return {
      provider: 'openai',
      blob,
      width: config.width,
      height: config.height,
      cost: config.estimatedCost,
      tier,
      quality: config.quality,
      model: this.imageModel
    };
  }
}

// === TIERED IMAGE PROVIDER CHAIN ===

async function generateTieredImage(prompt, tier, openaiClient, hfGenerator, hfToken) {
  const providers = getTieredProviderChain(tier, openaiClient, hfGenerator, hfToken);

  for (const provider of providers) {
    try {
      const result = await provider.generate(prompt, tier);
      if (result) return result;
    } catch (err) {
      console.warn(`${provider.name} failed for ${tier}, trying next...`, err.message);
      continue;
    }
  }

  throw new Error('All image providers failed');
}

function getTieredProviderChain(tier, openaiClient, hfGenerator, hfToken) {
  const hfProvider = {
    name: 'HuggingFace',
    async generate(prompt, tier) {
      if (!hfToken) throw new Error('No HuggingFace token');
      const size = tier === 'preview' ? 512 : 1024;
      const steps = tier === 'preview' ? 4 : 8;
      const blob = await hfGenerator.generateIllustrationHF(prompt, '', 'black-forest-labs/FLUX.1-schnell', { width: size, height: size, steps });
      return {
        provider: 'huggingface',
        blob: blob.blob || blob,
        width: size,
        height: size,
        cost: 0,
        tier
      };
    }
  };

  const openaiProvider = {
    name: 'OpenAI',
    async generate(prompt, tier) {
      return await openaiClient.generateTieredImage(prompt, tier);
    }
  };

  switch (tier) {
    case 'preview':
      return [hfProvider, ...(openaiClient.isConfigured() ? [openaiProvider] : [])];
    case 'standard':
      return [hfProvider, ...(openaiClient.isConfigured() ? [openaiProvider] : [])];
    case 'print':
      return [
        ...(openaiClient.isConfigured() ? [openaiProvider] : []),
        hfProvider
      ];
    default:
      return [hfProvider];
  }
}

// === PRINT UPSCALING ===

async function upscaleForPrint(imageBlob, targetWidth = 1800, targetHeight = 2700) {
  const img = await createImageBitmap(imageBlob);

  // Two-pass upscale for better quality
  const midCanvas = document.createElement('canvas');
  const midW = Math.round((img.width + targetWidth) / 2);
  const midH = Math.round((img.height + targetHeight) / 2);
  midCanvas.width = midW;
  midCanvas.height = midH;
  const midCtx = midCanvas.getContext('2d');
  midCtx.imageSmoothingEnabled = true;
  midCtx.imageSmoothingQuality = 'high';
  midCtx.drawImage(img, 0, 0, midW, midH);

  // Final pass
  const finalCanvas = document.createElement('canvas');
  finalCanvas.width = targetWidth;
  finalCanvas.height = targetHeight;
  const finalCtx = finalCanvas.getContext('2d');
  finalCtx.imageSmoothingEnabled = true;
  finalCtx.imageSmoothingQuality = 'high';
  finalCtx.drawImage(midCanvas, 0, 0, targetWidth, targetHeight);

  return new Promise(resolve => {
    finalCanvas.toBlob(resolve, 'image/png');
  });
}

// === QUALITY BADGE COMPONENT ===

function renderQualityBadge(image) {
  const badges = {
    preview: { label: 'Preview', color: '#6B7280', icon: '\uD83D\uDC41' },
    standard: { label: 'Standard', color: '#2563EB', icon: '\uD83D\uDCF1' },
    print: { label: 'Print Ready', color: '#059669', icon: '\uD83D\uDDA8' }
  };

  const badge = badges[image.tier] || badges.preview;
  const costStr = image.cost > 0 ? '$' + image.cost.toFixed(3) : 'FREE';
  return `<span class="quality-badge" style="display:inline-flex;align-items:center;gap:4px;padding:2px 8px;border-radius:4px;font-size:0.7rem;color:#fff;background:${badge.color};">${badge.icon} ${badge.label} \u00b7 ${image.width}\u00d7${image.height} \u00b7 ${image.provider} \u00b7 ${costStr}</span>`;
}

// === HELPERS ===

function base64ToBlob(base64, mimeType) {
  const binary = atob(base64);
  const bytes = new Uint8Array(binary.length);
  for (let i = 0; i < binary.length; i++) {
    bytes[i] = binary.charCodeAt(i);
  }
  return new Blob([bytes], { type: mimeType });
}

export { OpenAIClient, generateTieredImage, upscaleForPrint, renderQualityBadge, base64ToBlob };
